{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pretty-confusion-matrix\n!pip install transformers\n!pip install pytorch-transformers\n!pip install -U sentence-transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-05T18:42:57.631009Z","iopub.execute_input":"2022-12-05T18:42:57.631536Z","iopub.status.idle":"2022-12-05T18:44:10.632332Z","shell.execute_reply.started":"2022-12-05T18:42:57.631412Z","shell.execute_reply":"2022-12-05T18:44:10.630543Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pretty-confusion-matrix\n  Downloading pretty_confusion_matrix-0.1.1-py3-none-any.whl (9.6 kB)\nRequirement already satisfied: pandas<2.0.0,>=1.3.4 in /opt/conda/lib/python3.7/site-packages (from pretty-confusion-matrix) (1.3.5)\nRequirement already satisfied: sklearn<0.1,>=0.0 in /opt/conda/lib/python3.7/site-packages (from pretty-confusion-matrix) (0.0)\nCollecting flake8<4.0.0,>=3.9.2\n  Downloading flake8-3.9.2-py2.py3-none-any.whl (73 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.1/73.1 kB\u001b[0m \u001b[31m676.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting pre-commit<3.0.0,>=2.12.1\n  Downloading pre_commit-2.20.0-py2.py3-none-any.whl (199 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.5/199.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.21.4 in /opt/conda/lib/python3.7/site-packages (from pretty-confusion-matrix) (1.21.6)\nRequirement already satisfied: isort<6.0.0,>=5.8.0 in /opt/conda/lib/python3.7/site-packages (from pretty-confusion-matrix) (5.10.1)\nRequirement already satisfied: seaborn<0.12.0,>=0.11.2 in /opt/conda/lib/python3.7/site-packages (from pretty-confusion-matrix) (0.11.2)\nCollecting black<22.0,>=21.5b0\n  Downloading black-21.12b0-py3-none-any.whl (156 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.7/156.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: matplotlib<4.0.0,>=3.5.0 in /opt/conda/lib/python3.7/site-packages (from pretty-confusion-matrix) (3.5.3)\nRequirement already satisfied: typing-extensions>=3.10.0.0 in /opt/conda/lib/python3.7/site-packages (from black<22.0,>=21.5b0->pretty-confusion-matrix) (4.4.0)\nRequirement already satisfied: typed-ast>=1.4.2 in /opt/conda/lib/python3.7/site-packages (from black<22.0,>=21.5b0->pretty-confusion-matrix) (1.5.4)\nRequirement already satisfied: pathspec<1,>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from black<22.0,>=21.5b0->pretty-confusion-matrix) (0.9.0)\nRequirement already satisfied: platformdirs>=2 in /opt/conda/lib/python3.7/site-packages (from black<22.0,>=21.5b0->pretty-confusion-matrix) (2.5.1)\nRequirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.7/site-packages (from black<22.0,>=21.5b0->pretty-confusion-matrix) (0.4.3)\nRequirement already satisfied: click>=7.1.2 in /opt/conda/lib/python3.7/site-packages (from black<22.0,>=21.5b0->pretty-confusion-matrix) (8.0.4)\nCollecting tomli<2.0.0,>=0.2.6\n  Downloading tomli-1.2.3-py3-none-any.whl (12 kB)\nRequirement already satisfied: mccabe<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from flake8<4.0.0,>=3.9.2->pretty-confusion-matrix) (0.6.1)\nCollecting pyflakes<2.4.0,>=2.3.0\n  Downloading pyflakes-2.3.1-py2.py3-none-any.whl (68 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pycodestyle<2.8.0,>=2.7.0\n  Downloading pycodestyle-2.7.0-py2.py3-none-any.whl (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from flake8<4.0.0,>=3.9.2->pretty-confusion-matrix) (4.13.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib<4.0.0,>=3.5.0->pretty-confusion-matrix) (1.4.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib<4.0.0,>=3.5.0->pretty-confusion-matrix) (9.1.1)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib<4.0.0,>=3.5.0->pretty-confusion-matrix) (3.0.9)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib<4.0.0,>=3.5.0->pretty-confusion-matrix) (4.33.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib<4.0.0,>=3.5.0->pretty-confusion-matrix) (21.3)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib<4.0.0,>=3.5.0->pretty-confusion-matrix) (0.11.0)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib<4.0.0,>=3.5.0->pretty-confusion-matrix) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas<2.0.0,>=1.3.4->pretty-confusion-matrix) (2022.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from pre-commit<3.0.0,>=2.12.1->pretty-confusion-matrix) (6.0)\nRequirement already satisfied: virtualenv>=20.0.8 in /opt/conda/lib/python3.7/site-packages (from pre-commit<3.0.0,>=2.12.1->pretty-confusion-matrix) (20.15.1)\nCollecting cfgv>=2.0.0\n  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\nRequirement already satisfied: toml in /opt/conda/lib/python3.7/site-packages (from pre-commit<3.0.0,>=2.12.1->pretty-confusion-matrix) (0.10.2)\nCollecting identify>=1.0.0\n  Downloading identify-2.5.9-py2.py3-none-any.whl (98 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.8/98.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nodeenv>=0.11.1\n  Downloading nodeenv-1.7.0-py2.py3-none-any.whl (21 kB)\nRequirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.7/site-packages (from seaborn<0.12.0,>=0.11.2->pretty-confusion-matrix) (1.7.3)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sklearn<0.1,>=0.0->pretty-confusion-matrix) (1.0.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nodeenv>=0.11.1->pre-commit<3.0.0,>=2.12.1->pretty-confusion-matrix) (59.8.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.5.0->pretty-confusion-matrix) (1.15.0)\nRequirement already satisfied: filelock<4,>=3.2 in /opt/conda/lib/python3.7/site-packages (from virtualenv>=20.0.8->pre-commit<3.0.0,>=2.12.1->pretty-confusion-matrix) (3.7.1)\nRequirement already satisfied: distlib<1,>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from virtualenv>=20.0.8->pre-commit<3.0.0,>=2.12.1->pretty-confusion-matrix) (0.3.4)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->flake8<4.0.0,>=3.9.2->pretty-confusion-matrix) (3.8.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn<0.1,>=0.0->pretty-confusion-matrix) (1.0.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn<0.1,>=0.0->pretty-confusion-matrix) (3.1.0)\nInstalling collected packages: tomli, pyflakes, pycodestyle, nodeenv, identify, cfgv, flake8, pre-commit, black, pretty-confusion-matrix\n  Attempting uninstall: tomli\n    Found existing installation: tomli 2.0.1\n    Uninstalling tomli-2.0.1:\n      Successfully uninstalled tomli-2.0.1\n  Attempting uninstall: pyflakes\n    Found existing installation: pyflakes 2.4.0\n    Uninstalling pyflakes-2.4.0:\n      Successfully uninstalled pyflakes-2.4.0\n  Attempting uninstall: pycodestyle\n    Found existing installation: pycodestyle 2.8.0\n    Uninstalling pycodestyle-2.8.0:\n      Successfully uninstalled pycodestyle-2.8.0\n  Attempting uninstall: flake8\n    Found existing installation: flake8 4.0.1\n    Uninstalling flake8-4.0.1:\n      Successfully uninstalled flake8-4.0.1\n  Attempting uninstall: black\n    Found existing installation: black 22.6.0\n    Uninstalling black-22.6.0:\n      Successfully uninstalled black-22.6.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npytoolconfig 1.2.2 requires tomli>=2.0; python_version < \"3.11\", but you have tomli 1.2.3 which is incompatible.\nautopep8 1.6.0 requires pycodestyle>=2.8.0, but you have pycodestyle 2.7.0 which is incompatible.\nallennlp 2.10.0 requires protobuf==3.20.0, but you have protobuf 3.19.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed black-21.12b0 cfgv-3.3.1 flake8-3.9.2 identify-2.5.9 nodeenv-1.7.0 pre-commit-2.20.0 pretty-confusion-matrix-0.1.1 pycodestyle-2.7.0 pyflakes-2.3.1 tomli-1.2.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.13.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.4.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.9.24)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.12)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting pytorch-transformers\n  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pytorch-transformers) (1.21.6)\nRequirement already satisfied: boto3 in /opt/conda/lib/python3.7/site-packages (from pytorch-transformers) (1.24.93)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from pytorch-transformers) (0.1.97)\nRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-transformers) (1.11.0+cpu)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from pytorch-transformers) (0.0.53)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from pytorch-transformers) (2.28.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from pytorch-transformers) (4.64.0)\nRequirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from pytorch-transformers) (2021.11.10)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.0.0->pytorch-transformers) (4.4.0)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3->pytorch-transformers) (1.0.1)\nRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from boto3->pytorch-transformers) (0.6.0)\nRequirement already satisfied: botocore<1.28.0,>=1.27.93 in /opt/conda/lib/python3.7/site-packages (from boto3->pytorch-transformers) (1.27.93)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->pytorch-transformers) (2022.9.24)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->pytorch-transformers) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->pytorch-transformers) (1.26.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->pytorch-transformers) (3.3)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->pytorch-transformers) (8.0.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->pytorch-transformers) (1.15.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->pytorch-transformers) (1.0.1)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.28.0,>=1.27.93->boto3->pytorch-transformers) (2.8.2)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->sacremoses->pytorch-transformers) (4.13.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->pytorch-transformers) (3.8.0)\nInstalling collected packages: pytorch-transformers\nSuccessfully installed pytorch-transformers-1.2.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting sentence-transformers\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m930.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.20.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.64.0)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.11.0+cpu)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.12.0+cpu)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.21.6)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.0.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.7.3)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (3.7)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.1.97)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.10.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.7.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.13.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.11.10)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.12.1)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (8.0.4)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (1.0.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers) (3.1.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->sentence-transformers) (9.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (3.8.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.12)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.9.24)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=693c9788e9bace84f13495c58dcfa4ee29d551b7f886741e39c576b00cb81ca7\n  Stored in directory: /root/.cache/pip/wheels/bf/06/fb/d59c1e5bd1dac7f6cf61ec0036cc3a10ab8fecaa6b2c3d3ee9\nSuccessfully built sentence-transformers\nInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.2.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport csv\nimport pickle\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-12-05T18:44:10.635589Z","iopub.execute_input":"2022-12-05T18:44:10.636007Z","iopub.status.idle":"2022-12-05T18:44:10.643255Z","shell.execute_reply.started":"2022-12-05T18:44:10.635955Z","shell.execute_reply":"2022-12-05T18:44:10.641892Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras.layers import Bidirectional, Input, Dense, Layer, Dropout, LSTM, Embedding, Flatten\nfrom keras.models import Sequential, Model\nfrom tensorflow.python.keras.callbacks import EarlyStopping\nfrom keras import backend as K","metadata":{"execution":{"iopub.status.busy":"2022-12-05T18:44:10.644688Z","iopub.execute_input":"2022-12-05T18:44:10.645205Z","iopub.status.idle":"2022-12-05T18:44:16.806084Z","shell.execute_reply.started":"2022-12-05T18:44:10.645158Z","shell.execute_reply":"2022-12-05T18:44:16.804472Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"POLITENESS_LEVELS = 5\nEPOCHS = 30\nMAXLEN = 768 # Since SciBERT returns 768 embeddings vector\nLSTM_UNITS = 256\nis_BiLSTM = True # Flag to automate other pre-processing for With or Without BiLSTM variants\nVOCAB_LEN = 1853\nEMBEDDING_DIMENSION = 300","metadata":{"execution":{"iopub.status.busy":"2022-12-05T18:44:16.808444Z","iopub.execute_input":"2022-12-05T18:44:16.809289Z","iopub.status.idle":"2022-12-05T18:44:16.817533Z","shell.execute_reply.started":"2022-12-05T18:44:16.809251Z","shell.execute_reply":"2022-12-05T18:44:16.815460Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"start_path = '/kaggle/input/iitpolitenesslevels/'\n\nX_val = pd.read_csv(start_path+'val.csv')\ny_val = pd.read_csv(start_path+'y_val.csv') \n\n# LOAD EMBEDS\nLOAD_PATH = start_path+'SCIBERT'+'_val.pickle'\nwith open(LOAD_PATH, 'rb') as handle:\n    sci_val_embeds = pickle.load(handle)\n    sci_val_embeds = np.array([row[0] for row in sci_val_embeds ])\n    handle.close()\n \nLOAD_PATH = start_path+'HATE-BERT'+'_val.pickle'\nwith open(LOAD_PATH, 'rb') as handle:\n    hate_val_embeds = pickle.load(handle)\n    hate_val_embeds = np.array([row[0] for row in hate_val_embeds ])\n    handle.close()\n    \nLOAD_PATH = start_path+'TOXIC-BERT'+'_val.pickle'\nwith open(LOAD_PATH, 'rb') as handle:\n    toxic_val_embeds = pickle.load(handle)\n    toxic_val_embeds = np.array([row[0] for row in toxic_val_embeds ])\n    handle.close()\n\n\nLOAD_PATH = start_path+'Tokennized_Processed_X_val-BiLSTM.csv'\ncustom_val_embeds = pd.read_csv(LOAD_PATH)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-05T18:59:18.453259Z","iopub.execute_input":"2022-12-05T18:59:18.453806Z","iopub.status.idle":"2022-12-05T18:59:18.764775Z","shell.execute_reply.started":"2022-12-05T18:59:18.453769Z","shell.execute_reply":"2022-12-05T18:59:18.763789Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"X_val","metadata":{"execution":{"iopub.status.busy":"2022-12-05T18:59:20.070619Z","iopub.execute_input":"2022-12-05T18:59:20.071077Z","iopub.status.idle":"2022-12-05T18:59:20.093734Z","shell.execute_reply.started":"2022-12-05T18:59:20.071042Z","shell.execute_reply":"2022-12-05T18:59:20.092248Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"                                                review  HIMP  IMP  N  P  HP  \\\n0    The approach presented is simple , clearly pre...     0    0  1  0   0   \n1    One minor suggestion for improving readability...     0    0  1  0   0   \n2    It is at best of little value and, in the wors...     0    1  0  0   0   \n3    1.Are the samples sequenced? If yes, it will b...     0    0  0  0   1   \n4    Quality : Im intrigued by but a little uncomfo...     0    1  0  0   0   \n..                                                 ...   ...  ... .. ..  ..   \n279  This leads to the proposed algorithm called DA...     0    0  0  1   0   \n280  I also think that the authors might benefit fr...     0    0  0  1   0   \n281  From this perspective , I wish to see more mat...     0    0  1  0   0   \n282  Usually climate studies do not show a good met...     0    0  1  0   0   \n283  Though less enthused about manuscript's novelt...     0    1  0  0   0   \n\n     Tone  \n0     3.0  \n1     3.0  \n2     2.0  \n3     5.0  \n4     2.0  \n..    ...  \n279   4.0  \n280   4.0  \n281   3.0  \n282   3.0  \n283   2.0  \n\n[284 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>HIMP</th>\n      <th>IMP</th>\n      <th>N</th>\n      <th>P</th>\n      <th>HP</th>\n      <th>Tone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The approach presented is simple , clearly pre...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>One minor suggestion for improving readability...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>It is at best of little value and, in the wors...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.Are the samples sequenced? If yes, it will b...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Quality : Im intrigued by but a little uncomfo...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>279</th>\n      <td>This leads to the proposed algorithm called DA...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>280</th>\n      <td>I also think that the authors might benefit fr...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>281</th>\n      <td>From this perspective , I wish to see more mat...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>282</th>\n      <td>Usually climate studies do not show a good met...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>283</th>\n      <td>Though less enthused about manuscript's novelt...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>284 rows × 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## LOAD MODEL","metadata":{}},{"cell_type":"code","source":"class Attention(Layer):\n    \n    def __init__(self, return_sequences=True, **kwargs):\n        super(Attention,self).__init__()\n        self.return_sequences = return_sequences\n        super(Attention, self).__init__(**kwargs)\n\n    def get_config(self):\n        config = super(Attention, self).get_config().copy()\n        config.update({\n            'return_sequences': self.return_sequences , \n        })\n        return config\n\n\n    def build(self, input_shape):\n        \n        self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1],1),\n                               initializer=\"normal\")\n        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1),\n                               initializer=\"zeros\")\n        \n        super(Attention,self).build(input_shape)\n        \n    def call(self, x):\n        e =K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)\n        a =K.softmax(e)\n        a=K.expand_dims(a,axis=-1)\n        output = x*a\n        \n        return K.sum(output, axis=1) ","metadata":{"execution":{"iopub.status.busy":"2022-12-05T18:59:21.611639Z","iopub.execute_input":"2022-12-05T18:59:21.612477Z","iopub.status.idle":"2022-12-05T18:59:21.624030Z","shell.execute_reply.started":"2022-12-05T18:59:21.612435Z","shell.execute_reply":"2022-12-05T18:59:21.622426Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# LOAD MODEL\nfrom keras.models import load_model\ndef loadModel(name, PATH, X, y):\n    model = load_model(PATH, custom_objects={'Attention': Attention})\n    print(name+\" MODEL LOADED\\n\\n\")\n    model.evaluate(X, y)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-12-05T18:59:21.870841Z","iopub.execute_input":"2022-12-05T18:59:21.872090Z","iopub.status.idle":"2022-12-05T18:59:21.877877Z","shell.execute_reply.started":"2022-12-05T18:59:21.872034Z","shell.execute_reply":"2022-12-05T18:59:21.876937Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"### A) HATE-BERT","metadata":{}},{"cell_type":"code","source":"PATH = '/kaggle/input/iitpolitenesslevels/Politeness_HATE-BERT.h5'\nhateBert_model = loadModel('HATE-BERT', PATH, hate_val_embeds, y_val)","metadata":{"execution":{"iopub.status.busy":"2022-12-05T18:59:22.993303Z","iopub.execute_input":"2022-12-05T18:59:22.993798Z","iopub.status.idle":"2022-12-05T18:59:23.283244Z","shell.execute_reply.started":"2022-12-05T18:59:22.993764Z","shell.execute_reply":"2022-12-05T18:59:23.281853Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"HATE-BERT MODEL LOADED\n\n\n9/9 [==============================] - 0s 2ms/step - loss: 1.0624 - accuracy: 0.5915\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### B) SCIBERT","metadata":{}},{"cell_type":"code","source":"PATH = '/kaggle/input/iitpolitenesslevels/Politeness_SCIBERT.h5'\nsciBert_model = loadModel('SCIBERT', PATH, sci_val_embeds, y_val)","metadata":{"execution":{"iopub.status.busy":"2022-12-05T18:59:24.730957Z","iopub.execute_input":"2022-12-05T18:59:24.732040Z","iopub.status.idle":"2022-12-05T18:59:25.004503Z","shell.execute_reply.started":"2022-12-05T18:59:24.731997Z","shell.execute_reply":"2022-12-05T18:59:25.002890Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"SCIBERT MODEL LOADED\n\n\n9/9 [==============================] - 0s 2ms/step - loss: 0.9399 - accuracy: 0.6338\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### C) TOXIC-BERT","metadata":{}},{"cell_type":"code","source":"PATH = '/kaggle/input/iitpolitenesslevels/Politeness_TOXIC-BERT.h5'\ntoxicBert_model = loadModel('TOXIC-BERT', PATH, toxic_val_embeds, y_val)","metadata":{"execution":{"iopub.status.busy":"2022-12-05T18:59:27.231305Z","iopub.execute_input":"2022-12-05T18:59:27.231807Z","iopub.status.idle":"2022-12-05T18:59:27.494646Z","shell.execute_reply.started":"2022-12-05T18:59:27.231772Z","shell.execute_reply":"2022-12-05T18:59:27.493102Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"TOXIC-BERT MODEL LOADED\n\n\n9/9 [==============================] - 0s 2ms/step - loss: 0.8295 - accuracy: 0.6901\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### D) Custom Embed","metadata":{}},{"cell_type":"code","source":"PATH = '/kaggle/input/iitpolitenesslevels/Politeness_Custom-Embedding-BiLSTM.h5'\ncustom_model = loadModel('Custom Embed', PATH, custom_val_embeds, y_val)","metadata":{"execution":{"iopub.status.busy":"2022-12-05T19:05:19.264339Z","iopub.execute_input":"2022-12-05T19:05:19.265324Z","iopub.status.idle":"2022-12-05T19:05:33.849686Z","shell.execute_reply.started":"2022-12-05T19:05:19.265254Z","shell.execute_reply":"2022-12-05T19:05:33.848382Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Custom Embed MODEL LOADED\n\n\n9/9 [==============================] - 13s 1s/step - loss: 1.0221 - accuracy: 0.8838\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# VALIDATION","metadata":{}},{"cell_type":"code","source":"def adjustIndex(arr):\n    return [x+1 for x in arr]","metadata":{"execution":{"iopub.status.busy":"2022-12-05T19:46:43.752195Z","iopub.execute_input":"2022-12-05T19:46:43.752692Z","iopub.status.idle":"2022-12-05T19:46:43.759480Z","shell.execute_reply.started":"2022-12-05T19:46:43.752658Z","shell.execute_reply":"2022-12-05T19:46:43.757746Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"y_pred_SCI = sciBert_model.predict(sci_val_embeds)\ny_pred_HATE = hateBert_model.predict(hate_val_embeds)\ny_pred_TOXIC = toxicBert_model.predict(toxic_val_embeds)\ny_pred_Custom = toxicBert_model.predict(custom_val_embeds)\n\ny_pred_SCI_idx = adjustIndex(np.argmax(y_pred_SCI, axis=1))\ny_pred_HATE_idx = adjustIndex(np.argmax(y_pred_HATE, axis=1))\ny_pred_TOXIC_idx = adjustIndex(np.argmax(y_pred_TOXIC, axis=1))\ny_pred_Custom_idx = adjustIndex(np.argmax(y_pred_Custom, axis=1))\n\ny_val_true_idx = adjustIndex(np.argmax(y_val.values, axis=1))","metadata":{"execution":{"iopub.status.busy":"2022-12-05T19:47:20.011515Z","iopub.execute_input":"2022-12-05T19:47:20.012140Z","iopub.status.idle":"2022-12-05T19:47:20.334068Z","shell.execute_reply.started":"2022-12-05T19:47:20.012098Z","shell.execute_reply":"2022-12-05T19:47:20.333041Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"# CONCATENATE RESULTS\nresults = pd.DataFrame()\nresults['reviews'] = X_val.review\nresults['True_Val'] = y_val_true_idx\nresults['SciBert'] = y_pred_SCI_idx\nresults['HateBert'] = y_pred_HATE_idx\nresults['ToxicBert'] = y_pred_TOXIC_idx\nresults['CudstomEmbed'] = y_pred_Custom_idx\nresults","metadata":{"execution":{"iopub.status.busy":"2022-12-05T19:47:22.647241Z","iopub.execute_input":"2022-12-05T19:47:22.647754Z","iopub.status.idle":"2022-12-05T19:47:22.674996Z","shell.execute_reply.started":"2022-12-05T19:47:22.647719Z","shell.execute_reply":"2022-12-05T19:47:22.673573Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"                                               reviews  True_Val  SciBert  \\\n0    The approach presented is simple , clearly pre...         3        5   \n1    One minor suggestion for improving readability...         3        5   \n2    It is at best of little value and, in the wors...         2        2   \n3    1.Are the samples sequenced? If yes, it will b...         5        5   \n4    Quality : Im intrigued by but a little uncomfo...         2        5   \n..                                                 ...       ...      ...   \n279  This leads to the proposed algorithm called DA...         4        4   \n280  I also think that the authors might benefit fr...         4        4   \n281  From this perspective , I wish to see more mat...         3        2   \n282  Usually climate studies do not show a good met...         3        3   \n283  Though less enthused about manuscript's novelt...         2        5   \n\n     HateBert  ToxicBert  CudstomEmbed  \n0           4          4             3  \n1           4          4             5  \n2           2          2             2  \n3           5          5             2  \n4           5          4             1  \n..        ...        ...           ...  \n279         4          4             1  \n280         4          3             5  \n281         5          2             5  \n282         4          3             3  \n283         2          2             2  \n\n[284 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviews</th>\n      <th>True_Val</th>\n      <th>SciBert</th>\n      <th>HateBert</th>\n      <th>ToxicBert</th>\n      <th>CudstomEmbed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The approach presented is simple , clearly pre...</td>\n      <td>3</td>\n      <td>5</td>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>One minor suggestion for improving readability...</td>\n      <td>3</td>\n      <td>5</td>\n      <td>4</td>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>It is at best of little value and, in the wors...</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.Are the samples sequenced? If yes, it will b...</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Quality : Im intrigued by but a little uncomfo...</td>\n      <td>2</td>\n      <td>5</td>\n      <td>5</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>279</th>\n      <td>This leads to the proposed algorithm called DA...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>280</th>\n      <td>I also think that the authors might benefit fr...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>281</th>\n      <td>From this perspective , I wish to see more mat...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>5</td>\n      <td>2</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>282</th>\n      <td>Usually climate studies do not show a good met...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>4</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>283</th>\n      <td>Though less enthused about manuscript's novelt...</td>\n      <td>2</td>\n      <td>5</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>284 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"results.to_csv('baselines_val_labels.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-05T19:47:27.181468Z","iopub.execute_input":"2022-12-05T19:47:27.181925Z","iopub.status.idle":"2022-12-05T19:47:27.190269Z","shell.execute_reply.started":"2022-12-05T19:47:27.181890Z","shell.execute_reply":"2022-12-05T19:47:27.189006Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"correct = []\nfor index, row in results.iterrows():\n    labels = ['True_Val', 'SciBert', 'HateBert', 'ToxicBert', 'CudstomEmbed']\n#     print(row)\n    if sum(row[labels].values)/(len(labels)-1) == row['True_Val']:\n        correct.append(row)\n        \npd.DataFrame(correct)","metadata":{"execution":{"iopub.status.busy":"2022-12-05T19:33:23.976514Z","iopub.execute_input":"2022-12-05T19:33:23.977182Z","iopub.status.idle":"2022-12-05T19:33:24.147017Z","shell.execute_reply.started":"2022-12-05T19:33:23.977134Z","shell.execute_reply":"2022-12-05T19:33:24.145509Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"                                               reviews  True_Val  SciBert  \\\n10   In fact , it is not difficult to design exampl...         2        2   \n11   I showed this paper to my nurses and they agre...         1        1   \n17   Cite newer, relevant references, especially th...         4        4   \n19                                  This is very bad .         1        1   \n20   Please, consider carefully my comments in the ...         4        4   \n..                                                 ...       ...      ...   \n261  If such were present , Id rate this paper sign...         1        0   \n262             I congratulate the author for the work         4        4   \n265  Judging from the description of the experiment...         2        2   \n278            This looks like a work of pure fantasy.         1        1   \n279  This leads to the proposed algorithm called DA...         3        3   \n\n     HateBert  ToxicBert  CudstomEmbed  \n10          2          2             0  \n11          1          1             0  \n17          4          4             0  \n19          1          1             0  \n20          4          4             0  \n..        ...        ...           ...  \n261         1          2             0  \n262         4          4             0  \n265         2          2             0  \n278         1          1             0  \n279         3          3             0  \n\n[64 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviews</th>\n      <th>True_Val</th>\n      <th>SciBert</th>\n      <th>HateBert</th>\n      <th>ToxicBert</th>\n      <th>CudstomEmbed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>In fact , it is not difficult to design exampl...</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>I showed this paper to my nurses and they agre...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Cite newer, relevant references, especially th...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>This is very bad .</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Please, consider carefully my comments in the ...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>261</th>\n      <td>If such were present , Id rate this paper sign...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>262</th>\n      <td>I congratulate the author for the work</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>265</th>\n      <td>Judging from the description of the experiment...</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>278</th>\n      <td>This looks like a work of pure fantasy.</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>279</th>\n      <td>This leads to the proposed algorithm called DA...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>64 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}